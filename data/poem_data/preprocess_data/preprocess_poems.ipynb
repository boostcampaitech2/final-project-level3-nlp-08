{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 크롤링 데이터 전처리<br>\n",
    "Scrapy를 통해 List 형식으로 크롤링된 시를 str 형식으로 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import ast\n",
    "import hanja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from_teen = pd.read_csv(\"../raw_data/geulteen_poems.csv\").drop(\"Unnamed: 0\", axis=1)\n",
    "from_modern_poems = pd.read_csv(\"../raw_data/modern_poems_raw.csv\").drop(\"Unnamed: 0\", axis=1)\n",
    "from_dica_poems = pd.read_csv(\"../raw_data/dica_poems_raw.csv\").drop(\"Unnamed: 0\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"[poem]\" 형식의 str을 List인 [poem]으로 치환\n",
    "def listify(poem):\n",
    "    return ast.literal_eval(poem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from_teen['poem'] = from_teen['poem'].apply(listify)\n",
    "from_modern_poems['poem'] = from_modern_poems['poem'].apply(listify)\n",
    "from_dica_poems['poem'] = from_dica_poems['poem'].apply(listify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 리스트 안의 시 내용을 개행문자로 묶어줌. \n",
    "def strip_and_join_newline(poem_list):\n",
    "    return \"\\n\".join(map(str.strip, poem_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 데이터의 노이즈가 될 수 있는 부분 전처리\n",
    "KLUE 데이터셋의 전처리 방식을 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Klue 데이터셋 전처리 응용\n",
    "def preprocess(poem):\n",
    "    new = []\n",
    "    for text in poem:\n",
    "        # 문제를 일으킬 수 있는 문자 제거\n",
    "        bad_chars = {\"\\u200b\": \"\", \"…\": \" ... \", \"\\ufeff\": \"\"}\n",
    "        for bad_char in bad_chars:\n",
    "            text = text.replace(bad_char, bad_chars[bad_char])\n",
    "            \n",
    "        error_chars = {\"\\u3000\": \" \", \"\\u2009\": \" \", \"\\u2002\": \" \", \"\\xa0\":\" \"}\n",
    "        for error_char in error_chars:\n",
    "            text = text.replace(error_char, error_chars[error_char])\n",
    "\n",
    "        # URL 제거\n",
    "        text = re.sub(r\"(http|https)?:\\/\\/\\S+\\b|www\\.(\\w+\\.)+\\S*\", \"[웹주소]\", text).strip()\n",
    "        text = re.sub(r\"pic\\.(\\w+\\.)+\\S*\", \"[웹주소]\", text).strip()\n",
    "\n",
    "        # 뉴스 저작권 관련 텍스트 제거\n",
    "        re_patterns = [\n",
    "            r\"\\<저작권자(\\(c\\)|ⓒ|©|\\(Copyright\\)|(\\(c\\))|(\\(C\\))).+?\\>\",\n",
    "            r\"저작권자\\(c\\)|ⓒ|©|(Copyright)|(\\(c\\))|(\\(C\\))\"\n",
    "        ]\n",
    "        \n",
    "        for re_pattern in re_patterns:\n",
    "            text = re.sub(re_pattern, \"\", text).strip()\n",
    "        \n",
    "        # 뉴스 내 포함된 이미지에 대한 레이블 제거\n",
    "        text = re.sub(r\"\\(출처 ?= ?.+\\) |\\(사진 ?= ?.+\\) |\\(자료 ?= ?.+\\)| \\(자료사진\\) |사진=.+기자 \", \"\", text).strip()\n",
    "        \n",
    "        # 문제를 일으킬 수 있는 구두점 치환\n",
    "        punct_mapping = {\"‘\": \"'\", \"₹\": \"e\", \"´\": \"'\", \"°\": \"\", \"€\": \"e\", \"™\": \"tm\", \"√\": \" sqrt \", \"×\": \"x\", \"²\": \"2\", \"—\": \"-\", \"–\": \"-\", \"’\": \"'\", \"_\": \"-\", \"`\": \"'\", '“': '\"', '”': '\"', '“': '\"', \"£\": \"e\", '∞': 'infinity', 'θ': 'theta', '÷': '/', 'α': 'alpha', '•': '.', 'à': 'a', '−': '-', 'β': 'beta', '∅': '', '³': '3', 'π': 'pi', }\n",
    "        for p in punct_mapping:\n",
    "            text = text.replace(p, punct_mapping[p])\n",
    "        \n",
    "        # 연속된 공백 치환\n",
    "        text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "        \n",
    "        # 개행을 먼저 없애고 그 후 합쳐줌.\n",
    "        re.sub('\\n|\\t|\\r', \"\", text).strip()\n",
    "        re.sub('\\xa0', \" \", text).strip()\n",
    "\n",
    "        if text:\n",
    "            new.append(text)\n",
    "    return \"\\n\".join(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from_teen['poem'] = from_teen['poem'].apply(preprocess)\n",
    "from_modern_poems['poem'] = from_modern_poems['poem'].apply(preprocess)\n",
    "from_dica_poems['poem'] = from_dica_poems['poem'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 한자 전처리\n",
    "한자 전처리가 없을 시, 모델이 적절하지 않은 한자어를 생성하는 경우가 있음을 확인, 데이터의 한자를 제거 및 번역"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한글과 병기된 한자어는 삭제 후, 남은 한자어는 번역\n",
    "def hanja_preprocess(txt):\n",
    "    new = re.sub(r\"\\([\\u2e80-\\u2eff\\u31c0-\\u31ef\\u3200-\\u32ff\\u3400-\\u4dbf\\u4e00-\\u9fbf\\uf900-\\ufaff]+\\)|\\[[\\u2e80-\\u2eff\\u31c0-\\u31ef\\u3200-\\u32ff\\u3400-\\u4dbf\\u4e00-\\u9fbf\\uf900-\\ufaff]+\\]\", \"\", txt)\n",
    "    new = hanja.translate(new, 'substitution')\n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from_teen['poem'] = from_teen['poem'].apply(hanja_preprocess)\n",
    "from_modern_poems['poem'] = from_modern_poems['poem'].apply(hanja_preprocess)\n",
    "from_dica_poems['poem'] = from_dica_poems['poem'].apply(hanja_preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. CSV 형식으로 Export\n",
    "같은 형식으로 응용 가능한 teen과 modern_poems는 하나로 concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from_teen.to_csv(\"teen.csv\")\n",
    "from_modern_poems.to_csv(\"modern_poems.csv\")\n",
    "from_dica_poems.to_csv(\"dica_poems.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.concat([from_teen, from_modern_poems])\n",
    "train_data.to_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 기타 전처리\n",
    "인터넷 게시판의 시를 크롤링 했기에, 코드 외적으로 수정할 부분들이 많았습니다.<br>\n",
    "____, ----, ++++, 등으로 시작하는 분리(?) 마커 뒤에 개인적인 시에 대한 코멘트를 덧붙이는 경우,<br>\n",
    "dica_poems는 작가명(개인정보)이 같이 크롤링 된 경우,<br>\n",
    "주석을 단어에 *, 1) 등의 표시를 해둔 후 글 마지막에 설명하는 경우 등이 있었습니다.<br>\n",
    "또한, 현대시 형식으로 띄어쓰기 없이 작성된 시들, 특수문자만 사용한 시들 등은 상당부분 직접 확인하고 삭제했습니다."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e31c68abf1d5dd3f9e2269f23eadf1b199587e56c0618a30760176a65ebfcab4"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('lightweight': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
